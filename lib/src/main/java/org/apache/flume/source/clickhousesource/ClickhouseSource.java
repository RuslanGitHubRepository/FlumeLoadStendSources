/*
 * This Java source file was generated by the Gradle 'init' task.
 */
package org.apache.flume.source.clickhousesource;

import com.google.gson.JsonArray;
import org.apache.flume.Context;
import org.apache.flume.EventDeliveryException;
import org.apache.flume.FlumeException;
import org.apache.flume.conf.Configurable;
import org.apache.flume.event.JSONEvent;
import org.apache.flume.source.AbstractPollableSource;
import org.apache.flume.source.clickhousesource.clickhouse.ClickHouseConnectionConfig;
import org.apache.flume.source.clickhousesource.clickhouse.ClickHouseConnectionPool;
import org.apache.flume.source.clickhousesource.clickhouse.ClickHouseConnectionPoolConfig;
import org.apache.flume.source.clickhousesource.clickhouse.ClickHouseUtils;
import org.apache.flume.source.clickhousesource.clickhouse.ConnectionDecorator;
import org.apache.flume.source.clickhousesource.clickhouse.ReQueryParam;
import org.apache.flume.source.clickhousesource.clickhouse.ResultHandler;
import org.apache.flume.source.clickhousesource.model.JsonMonitoringActivity;
import org.apache.flume.source.clickhousesource.model.MonitoringActivity;
import org.checkerframework.checker.nullness.qual.NonNull;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import ru.yandex.clickhouse.ClickHouseConnection;
import ru.yandex.clickhouse.ClickHouseConnectionImpl;
import ru.yandex.clickhouse.settings.ClickHouseProperties;
import ru.yandex.clickhouse.settings.ClickHouseQueryParam;

import java.sql.SQLException;
import java.time.Duration;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

public class ClickhouseSource extends AbstractPollableSource implements Configurable {
    private static final Logger log = LoggerFactory.getLogger(ClickhouseSource.class);
    private static final Integer MAX_POOL_SIZE = 10;
    private static final Integer SQL_QUERY_QUEUE_SIZE = 10;
    private static final Duration SOCKET_TIMEOUT = Duration.ofSeconds(10);
    private static final Integer BACTH_SIZE = 10;
    private static final String HOST = "host";
    private static final String PORT = "port";
    private static final String USER = "user";
    private static final String PASSWORD = "password";
    private static final String SSL = "ssl";
    private static final String TABLE = "table";

    private String host;
    private short port;
    private String user;
    private String password;
    private boolean ssl;
    private String table;
    private Long id = 0L;

    private Integer lastResponseIndex = 0;

    private ClickHouseConnectionPool connectionPool;

    @Override
    protected void doConfigure(Context context) throws FlumeException {
        host = context.getString(HOST);
        port = context.getInteger(PORT, 8123).shortValue();
        user = context.getString(USER);
        password = context.getString(PASSWORD);
        table = context.getString(TABLE);
        ssl = context.getBoolean(SSL, Boolean.FALSE);
        log.info("Configure Clickhouse source has completed");
    }

    @Override
    public synchronized void doStart() {
        log.info("doStart method invoked");
        ClickHouseProperties clickHouseProperties = new ClickHouseProperties();
        clickHouseProperties.setHost(host);
        clickHouseProperties.setPort(port);
        clickHouseProperties.setUser(user);
        clickHouseProperties.setSsl(ssl);
        clickHouseProperties.setSocketTimeout(Long.valueOf(SOCKET_TIMEOUT.getSeconds()).intValue());
        clickHouseProperties.setPassword(password);
        clickHouseProperties.setSslRootCertificate(null);
        this.connectionPool = new ClickHouseConnectionPool(
                clickHouseProperties,
                MAX_POOL_SIZE,
                SQL_QUERY_QUEUE_SIZE);
    }

    @Override
    public synchronized void doStop() {
        log.info("doStop method invoked");
        this.connectionPool.reset();
    }

    @Override
    protected Status doProcess() throws EventDeliveryException {
        Status status = null;
        try {
            List<MonitoringActivity> monitoringActivities = execQuery(
                    String.format("SELECT * FROM %s WHERE id > %d ORDER BY %s LIMIT %d", table, id, "id", BACTH_SIZE),
                    resultSet -> {
                        List<MonitoringActivity> result = new ArrayList<>();
                        while (resultSet.next()) {
                            result.add(new MonitoringActivity(resultSet));
                        }
                        return result;
                    }
            );
            if(!monitoringActivities.isEmpty()) {
                id = monitoringActivities.listIterator(monitoringActivities.size()).previous().getId();
            }
            JSONEvent jsonEvent = new JSONEvent();
            HashMap<String, String> headers = new HashMap<>();
            headers.put("count_elements", String.valueOf(monitoringActivities.size()));
            JsonArray activityJSON = new JsonArray();
            monitoringActivities.stream()
                    .map(JsonMonitoringActivity::new)
                    .map(JsonMonitoringActivity::toJSONObject)
                    .forEach(activityJSON::add);
            jsonEvent.setBody(activityJSON.toString().getBytes());
            jsonEvent.setHeaders(headers);
            getChannelProcessor().processEvent(jsonEvent);
            log.info("Last id index from table {} is {}", table, id);
            status = Status.READY;
        } catch (FlumeException ex) {
            status = Status.BACKOFF;
        }
        log.info("Current status selection is {}", status);
        return status;
    }

    private <T> T execQuery(String query, @NonNull ResultHandler<T> handler) throws FlumeException {
        try (ConnectionDecorator connection = connectionPool.getConnection()) {
            if (connection.getConnection().isWrapperFor(ClickHouseConnectionImpl.class)) {
                ClickHouseConnection clickHouseConnection = connection.getConnection().unwrap(ClickHouseConnectionImpl.class);
                Map<String, String> additionalRequestParams = new HashMap<>();
                HashMap<ClickHouseQueryParam, String> additionalDBParams = new HashMap<>();
                additionalDBParams.put(ClickHouseQueryParam.CONNECT_TIMEOUT, "10000");
                additionalDBParams.put(ClickHouseQueryParam.DATABASE, "main");
                additionalRequestParams.put("enable_scalar_subquery_optimization", "0");
                return ClickHouseUtils.executeWithRepeat(
                        clickHouseConnection,
                        query,
                        handler,
                        additionalDBParams,
                        additionalRequestParams,
                        new ReQueryParam() {});

            } else {
                throw new RuntimeException("Not supported unwrap ClickHouse connection");
            }
        } catch (SQLException e) {
            throw new FlumeException(e);
        }
    }
}
